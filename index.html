<!DOCTYPE html>
<html lang="en">
<head>

  <!-- Basic Page Needs
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <meta charset="utf-8">
  <title>Your page title here :)</title>
  <meta name="description" content="">
  <meta name="author" content="">

  <!-- Mobile Specific Metas
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- FONT
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link href="https://fonts.googleapis.com/css?family=Raleway:400,300,600" rel="stylesheet" type="text/css">

  <!-- CSS
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="stylesheet" href="./css/normalize.css">
  <link rel="stylesheet" href="./css/skeleton.css">

  <!-- OverlayScrollbars Plugin CSS -->
  <link type="text/css" href="./lib/OverlayScrollbars-1.13.1/css/OverlayScrollbars.css" rel="stylesheet"/>

  <link rel="stylesheet" href="./css/colors.css">

  <!-- Favicon
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="icon" type="image/png" href="./images/favicon.png">

  <!-- JQuery script setup -->
  <script type="text/javascript" src="./lib/jquery/jquery-3.6.0.min.js"></script>

  <!-- OverlayScrollbars Plugin JS -->
  <script type="text/javascript" src="./lib/OverlayScrollbars-1.13.1/js/jquery.overlayScrollbars.js"></script>
  <script type="text/javascript">
    document.addEventListener("DOMContentLoaded", function() {
      $(function() {
          //The passed argument has to be at least a empty object or a object with your desired options
          $('body').overlayScrollbars({
            className : "custom-scrollbar os-theme-dark",
            scrollbars: {
              autoHide: "scroll",
              autoHideDelay: 800
            }
          });
      });
    });
  </script>
</head>
<body>

  <!-- Primary Page Layout
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <div style="width: calc(100% + 28px); height: 500px; overflow: hidden; margin-left: -14px">
    <div class='tableauPlaceholder' id='viz1634261980965' style='position: relative; overflow: hidden; margin-left: 0px; margin-top: -16px; margin-right: 0px; margin-bottom:-41px;'>
      <noscript>
        <a href='#'>
          <img alt='Map Dashboard' src='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;76&#47;76SKJ9YJ9&#47;1_rss.png' style='border: none' />
        </a>
      </noscript>
      <object class='tableauViz'  style='display:none;'>
        <param name='host_url' value='https%3A%2F%2Fpublic.tableau.com%2F' />
        <param name='embed_code_version' value='2' />
        <param name='path' value='shared&#47;76SKJ9YJ9' />
        <param name='toolbar' value='no' />
        <param name='static_image' value='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;76&#47;76SKJ9YJ9&#47;1.png' />
        <param name='animate_transition' value='yes' />
        <param name='display_static_image' value='yes' />
        <param name='display_spinner' value='yes' />
        <param name='display_overlay' value='yes' />
        <param name='display_count' value='yes' />
        <param name='language' value='en-US' />
        <param name='filter' value='publish=yes' />
      </object>
    </div>
    <script type='text/javascript'>
      var divElement = document.getElementById('viz1634261980965');
      var vizElement = divElement.getElementsByTagName('object')[0];
      if ( divElement.offsetWidth > 800 ) {
        vizElement.style.width='100%';
        vizElement.style.height=(divElement.offsetWidth*0.75)+'px';
      } else if ( divElement.offsetWidth > 500 ) {
        vizElement.style.width='100%';
        vizElement.style.height=(divElement.offsetWidth*0.75)+'px';
      } else {
        vizElement.style.width='100%';vizElement.style.height='727px';
      }
      var scriptElement = document.createElement('script');
      scriptElement.src = 'https://public.tableau.com/javascripts/api/viz_v1.js';
      vizElement.parentNode.insertBefore(scriptElement, vizElement);
    </script>
  </div>
  <div class="container">
    <div class="row" style="text-align: center">
      <h2 style="margin-top: 16px">A CARTOGRAPHY OF CARTOGRAPHY</h2>
      <h6 style="margin-top: -24px"><b><i>Or How I Learned to Stop Worrying and Make This Map</i></b></h6>
    </div>
    <div class="row" style="margin-top: 50%">
      <div class="offset-by-two eight columns">
        <h4>Part 1: The Dataset</h4>
      </div>
    </div>
    <div class="row" style="margin-top: 50%">
      <div class="offset-by-two eight columns">
        <p>Somewhere, probably in Virginia, there exists the virgin tweet.</p>
        <p>Untouched by a data-cleaner’s grubby hands, a database has a record of a tweet in its purest form: the form that Twitter’s API serves to the user when called to.</p>
        <p>A tweet has metadata. It isn’t just a picture, a video, or a 140 word piece of writing. A tweet also includes things like location, time of tweet, user who tweeted it. The reply and retweet functions add more complexity: a tweet then has subtweets and parent tweets, number of retweets and replies. Tweets even often include what device they were tweeted from:</p>
      </div>
    </div>
    <div class="row card" style="margin-top: 36px">
      <div class="img-container">
        <img alt="A tweet from an LG Smart Fridge" src="images/lg_smart_fridge.jpg"></img>
      </div>
      <p style="margin-top: -24px"><i>A user appears to tweet from their LG Smart Fridge. Metadata can be funny.</i></p>
    </div>
    <div class="row" style="margin-top: 36px">
      <div class="offset-by-two eight columns">
        <p>All of this information is captured and generated by someone’s phone running the Twitter app (or their browser, or even refrigerator). This information is then sent to Twitter, who in turn serves it to other users.</p>
        <p>Social media largely functions on this centralized model. A provider is served content by users--mediated, of course, through a user’s client. They then serve that content back to other users when other users request new Tweets. All of this purely ‘functional’ data is mediated through a social media client, which introduces its own limitations: the requirement to have an account, birth date confirmation before viewing a lewd image, warnings before you yourself post something vulgar, etc.</p>
        <p>But once these bundles of metadata and tweet data themselves emerge from a Twitter client and cross the communications infrastructure to Twitter’s datacenters, they become ripe for harvest: Twitter provides tweets for research purposes.</p>
      </div>
    </div>
    <div class="row" style="margin-top: 50%">
      <div class="offset-by-two eight columns">
        <h4>Part 2: The Transformations</h4>
      </div>
    </div>
    <div class="row" style="margin-top: 50%">
      <div class="offset-by-two eight columns">
        <p>In this project, I began with a simple proposition: I want to scrape some Twitter data. And I also wanted it to be funny.</p>
        <p>This, although seemingly straightforward, is actually pretty hard to do</p>
        <p>One approach would be to log on to Twitter and manually collect tweets. This would be impossibly slow for any significant amount of tweets. The other option would be to use some sort of automated script to log on to Twitter for me and then collect tweets. This sort of works, but runs into various issues. Many social media search algorithms, for instance, take into account a user’s history and interests in order to provide better results. While perhaps more efficient for the average human user, for a researcher, this means the data you are collecting is not necessarily representative.</p>
        <p>Deus ex application programming interface: Twitter has an API.</p>
        <p>Most web services do. An API is usually employed internally to serve bits of data between pieces of Twitter. A logon service queries a database for usernames; A Twitter client queries a database for new tweets. But it doesn’t always have to be internal: web services can provide limited API access to third parties. These third parties are usually vetted, and are made sure to be using this data responsibly.</p>
        <p>Twitter has particular concern about this: people tweet all sorts of things. Current locations, dark secrets, nude photos. If anyone could go querying Twitter for specific tweets, things would go poorly.</p>
        <p>Twitter then has developed two strategies for managing this API access. The first is to delineate access: they give specific portions of their overall tweet data to specific research institutions. They trust that these entities will use the data responsibly, and follow research ethics guidelines. (Such as keeping personal information private--which happens to be particularly difficult in the context of tweets: they have a lot of correlatable metadata).</p>
        <p>The other strategy Twitter employs to keep data-accessors in line is to have terms of use. The institution I got a subset of tweets from, for instance, is George Washington University. They have an online tool called <a href="https://tweetsets.library.gwu.edu/">TweetSets</a>, which allows for users to access a list of tweet identifiers based on a query.</p>
        <p>Data ethics come into play here though: Twitter forbids users of the API from publicly posting tweet text. However, according to TweetSets: “they do allow the sharing of tweet ids.” This creates a strange loophole: Twitter simultaneously denounces the propagation of publicly identifying tweet information while explicitly allowing API users to share the most identifiable aspect of a tweet: its identifier.</p>
        <p>As TweetSets points out: “Given a tweet id, the text of tweets can be retrieved from the Twitter API using a tool such as <a href="https://github.com/DocNow/hydrator">DocNow's Hydrator</a>.” TweetSets therefore suggested a plan. In fact, the website I discovered TweetSets on, “<a href="https://programminghistorian.org/en/lessons/beginners-guide-to-twitter-data#selecting-a-dataset">Beginner’s Guide to Twitter Data</a>,” suggested the same course of action: select a subset of tweets from GWU’s tool, then ‘hydrate’ those tweet identifiers to produce a richer data set.</p>
        <p>But I wanted my end product to be funny. So I tried to find strange connections in these datasets, which were all fairly sanitary tweets from public institutions.</p>
        <p>The first attempt I believe was looking for swear words. A few other attempts of equally silly search queries turned up equally uninteresting results. Then it hit me: Drake.</p>
        <p>I was going to look for the intersection of sterilized public institution Twitter accounts with the music industry.</p>
        <p>I had to first get a list of artist names though.</p>
        <p>This proved pretty difficult. I had no trouble finding <a href="https://chartmasters.org/most-streamed-artists-ever-on-spotify/">a website listing the top 1000 artists on Spotify</a>, however, they never provided a spreadsheet of their data table. Instead, I had to download the website’s source code, and extract the relevant information from the data table using Python. I did that, and tried searching for my list of artists. However, I again ran into issues. Tweets would match “Sia” with “Malaysia” or “MGMT” with “water mgmt.”</p>
        <p>Practically none of my tweets were about the musical artists themselves.</p>
        <p>It took me a while, but I eventually settled on the following rules for inclusion of a “searchable” music artist name:</p>
        <ol>
          <li>A name be spelled incorrectly and five characters or longer</li>
          <li>Or the name must be more than five words long.</li>
        </ol>
        <p>This produced a list of names that started to match with mostly artists. However, I wasn’t getting that many matches. So, I tried other subsets of tweets.</p>
        <p>The subset I settled on was simply titled “News Outlets.” To help narrow my data down further--there are 155,744,070 tweets that were available in that subset alone--I requested only tweets with geographic location. This gave me a workable number of tweets: 2533.</p>
        <p>Thus, after booting up DocHydrator, and manipulating the resultant spreadsheets further (I ended up filling specific latitude and longitude data based on queries to OpenStreetMaps’ Nominatim API) I had a final set of data to work with. The two lineages of data had combined into a final product: data I got from GWU, who got their data from Twitter, as well as data I got from Chartmasters.org, who presumably got their data from Spotify.</p>
      </div>
    </div>
    <div class="row" style="margin-top: 50%">
      <div class="offset-by-two eight columns">
        <h4>Part 3: The Visualizations</h4>
      </div>
    </div>
    <div class="row" style="margin-top: 50%">
      <div class="offset-by-two eight columns">
        <p>While the data set I crafted was rather painstakingly made, it only had a few interesting dimensions--namely the tweet metadata. (I also, at least compared to my experience with Python, am not skilled with Tableau). My visualizations thus were rather straightforward.</p>
        <p>I ended up settling on visualizing retweets counts in several different ways. I chose retweets as a generic metric of engagement with an artist or the paparazzi surrounding them. (More on this later). In Tableau, I plotted retweets against language first, and this proved the easiest graph to produce.</p>
      </div>
    </div>
    <div class="row card" style="margin-top: 36px">
      <div class="img-container">
        <img class="no-shadow" alt="A plot of average retweet count by tweet language. English and Spanish are in first and second, respectively." src="images/graph_1.png"></img>
      </div>
      <p style="margin-top: -24px"><i>Average retweet counts plotted against a tweet's "lang" metadata tag.</i></p>
    </div>
    <div class="row" style="margin-top: 36px">
      <div class="offset-by-two eight columns">
        <p>Next, I wanted to see which artists had a Twitter network with high engagement. I figured retweets would again be a good metric for this. I quickly ran into an issue though: I had no field in my spreadsheet for individual artists.</p>
        <p>To solve this issue, I returned once more to cleaning my data, this time writing a quick-and-dirty Python script that added a column to my spreadsheet with any names of artists matched within the text of the tweet. This, strangely enough, didn’t always produce a hit. But I went with it anyway.</p>
        <p>I then plotted this artist inclusion data against average retweet count. To no surprise, a KPOP group was #1:</p>
      </div>
    </div>
    <div class="row card" style="margin-top: 36px">
      <div class="img-container">
        <img class="no-shadow" alt="A plot of average retweet count by relevant spotify top 1000 artist. KPOP group BLACKPINK is #1." src="images/graph_0.png"></img>
      </div>
      <p style="margin-top: -24px"><i>Average retweet are topped by BLACKPINK. Of course.</i></p>
    </div>
    <div class="row" style="margin-top: 36px">
      <div class="offset-by-two eight columns">
        <p>Lastly, I began on my most ambitious visualization. As soon as I saw the “geotagged” checkbox on TweetSets, I knew I was going to make a map:</p>
      </div>
    </div>
  </div>
  <div style="width: calc(100% + 28px); height: 66%; margin-left: -14px; margin-right: -14px; margin-top: -11px; overflow: hidden">
    <div class='tableauPlaceholder' id='viz1634281817168' style='position: relative; overflow: hidden; margin-left: 0px; margin-top: -16px; margin-right: 0px; margin-bottom:-41px;'>
      <noscript>
        <a href='#'><img alt='Map Dash ' src='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;Sp&#47;SpotifyTop1000intheMediaTheTweetsMap&#47;MapDash&#47;1_rss.png' style='border: none' /></a>
      </noscript>
      <object class='tableauViz'  style='display:none;'>
        <param name='host_url' value='https%3A%2F%2Fpublic.tableau.com%2F' />
        <param name='embed_code_version' value='3' />
        <param name='site_root' value='' />
        <param name='name' value='SpotifyTop1000intheMediaTheTweetsMap&#47;MapDash' />
        <param name='tabs' value='no' />
        <param name='toolbar' value='yes' />
        <param name='static_image' value='https:&#47;&#47;public.tableau.com&#47;static&#47;images&#47;Sp&#47;SpotifyTop1000intheMediaTheTweetsMap&#47;MapDash&#47;1.png' />
        <param name='animate_transition' value='yes' />
        <param name='display_static_image' value='yes' />
        <param name='display_spinner' value='yes' />
        <param name='display_overlay' value='yes' />
        <param name='display_count' value='yes' />
        <param name='language' value='en-US' />
      </object>
    </div>
    <script type='text/javascript'>
    var divElement = document.getElementById('viz1634281817168');
    var vizElement = divElement.getElementsByTagName('object')[0];
     if ( divElement.offsetWidth > 800 ) {
       vizElement.style.width='100%';vizElement.style.height=(divElement.offsetWidth*0.5)+'px';
     } else if (
       divElement.offsetWidth > 500 ) {
       vizElement.style.width='100%';
       vizElement.style.height=(divElement.offsetWidth*0.75)+'px';
     } else {
       vizElement.style.width='100%';
       vizElement.style.height='727px';
     }
     var scriptElement = document.createElement('script');
     scriptElement.src = 'https://public.tableau.com/javascripts/api/viz_v1.js';                    vizElement.parentNode.insertBefore(scriptElement, vizElement);
     </script>
  </div>
  <div class="container">
    <div class="row" style="margin-top: 36px">
      <div class="offset-by-two eight columns">
        <p>This map is the most complex visualization. It includes two data points besides location:</p>
        <ul>
          <li>Tweet text, which connects the aggregated, globalized map-of-everything perspective to the individual action of tweeting.</li>
          <li>It also includes retweet count, in the form of a heatmap. Points are colored based on the engagement they drove.</li>
        </ul>
        <p>These three plots comprised my visualization step.</p>
      </div>
    </div>
    <div class="row" style="margin-top: 50%">
      <div class="offset-by-two eight columns">
        <h4>Part 4: The Discussion</h4>
      </div>
    </div>
    <div class="row" style="margin-top: 50%">
      <div class="offset-by-two eight columns">
        <p>My data got dirtier every time I cleaned it.</p>
        <p>At every step of the process to produce a workable set of data, I found myself having to erase data points, close fields of exploration, and put blind faith in a number of faceless corporate or academic institutions.</p>
        <p>When trying to produce a queryable list of artist names, for instance, I actively tried to erase data. I swore every time I came across another English word that had somehow defied my spellchecker. (The artist “fun.” stayed in my list undetected for a while causing many more tweets to show up than I wanted).</p>
        <p>When visualizing my end result data, I also find that a worrying amount of tweets ended up in Antarctica. In retrospect, it is obvious to me that I probably had flipped latitudes and longitudes of some entries by accident, but nonetheless these false results ended up in my final product.</p>
        <p>I also tended to use retweets as a metric for engagement. This privileging of retweets, or even of engagement itself, lends itself to selecting for digital experiences that breed outrage. That’s why news sites often have comments sections when they seem unnecessary: getting into an argument in one keeps you coming back; it drives up ad revenue and website standing in search engines.</p>
        <p>As Gitelman & Jackson (2013) said in Raw Data is an Oxymoron, “at a certain level the collection and management of data may be said to presuppose interpretation” (p. 3). I would go further: Interpretation requires intent. Even unwittingly, (as in the case of the Antarctic music paparazzi) manipulation of data constructs new truth itself, inherently detached from whatever original truth was embedded in those Tweets and their metadata.</p>
        <p>The tools I used to arrive at a final set of data, whether they be websites from George Washington University or the many Python libraries I employed, all of them presented themselves as though they were unbiased. No disclaimers of interpretive possibilities were presented to me upon my use of them. Yet, even something so innocuous as a Panda 1.3.3, a Python library to manipulate spreadsheets, left its mark on my data: the spreadsheet produced by DocHydrator started on the “coordinates” column, while my manipulated version had a column with row indices.</p>
        <p>This discussion of Python libraries segways nicely into my final point on the biases of my data: the privilege of the process itself. Not everyone knows how to use Python. Not everyone can even follow along with a tutorial about downloading tweet data. Hell, not everyone can even access the internet in the first place. Even I fell short: I couldn’t comprehend most of the Twitter legal that I was agreeing to by utilizing tweet data. As D’Ignazio & Klein (2016) put it: “Whose voices are not represented on the design team but might be important for the conceptualization of the project?” (2). Whose voices are missing in this exploration?</p>
        <p>Both technical skill and institutional access guard big data today. Both are intensely intersectional issues. Data processing must be understood therefore as a piece of a much larger puzzle.</p>
      </div>
    </div>
    <div class="row" style="margin-top: 50%">
      <div class="offset-by-two eight columns">
        <h6>References</h6>
        <p>D’Ignazio, Catherine, and Lauren F. Klein. “Feminist Data Visualization.” In Workshop on Visualization for the Digital Humanities (VIS4DH). Baltimore, 2016. <a href="http://www.kanarinka.com/wp-content/uploads/2015/07/IEEE_Feminist_Data_Visualization.pdf">http://www.kanarinka.com/wp-content/uploads/2015/07/IEEE_Feminist_Data_Visualization.pdf</a></p>
        <p>Gitelman, Lisa, and Virginia Jackson. “Introduction.” In “Raw Data” Is an Oxymoron, edited by Lisa Gitelman, 1–14. Cambridge, Massachusetts: The MIT Press, 2013.</p>
      </div>
    </div>
  </div>


<!-- End Document
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
</body>
</html>
